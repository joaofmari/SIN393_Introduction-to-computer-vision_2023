{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23eb889c",
   "metadata": {},
   "source": [
    "SIN-393 - Introduction to Computer Vision (2023-2)\n",
    "\n",
    "# Lecture 09 - Semantic segmentation\n",
    "\n",
    "Prof. João Fernando Mari ([*joaofmari.github.io*](https://joaofmari.github.io/))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf66c02",
   "metadata": {},
   "source": [
    "* Based on the tutorial:\n",
    "    * U-Net: Training Image Segmentation Models in PyTorch\n",
    "        * https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/\n",
    "* The U-Net implementation was based on:\n",
    "    * U-Net: A PyTorch Implementation in 60 lines of Code\n",
    "        * https://amaarora.github.io/2020/09/13/unet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ddf4f",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4ae115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdecc39",
   "metadata": {},
   "source": [
    "##  Conjunto de dados\n",
    "---\n",
    "\n",
    "* TGS Salt Identification Challenge\n",
    "    * https://www.kaggle.com/c/tgs-salt-identification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5ca8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o conjunto de imagens\n",
    "DS_PATH = '/home/joao/Datasets/TGS Salt Identification/competition_data/train/'\n",
    "\n",
    "# Caminho da pasta com as imagens\n",
    "IMAGE_PATH = os.path.join(DS_PATH, \"images\")\n",
    "# Caminho para a pasta com as máscaras\n",
    "MASK_PATH = os.path.join(DS_PATH, \"masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293547c",
   "metadata": {},
   "source": [
    "## Configurando acesso à GPU\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bab4c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "# determine if we will be pinning memory during data loading\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dd2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de aprendizado\n",
    "INIT_LR = 0.001\n",
    "# Número total de épocas de treinamento\n",
    "NUM_EPOCHS = 20 # 40\n",
    "# Tamanho do mini-lote\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Limiar para gerar imagem segmentada\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147c6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de canais nas imagens de entrada\n",
    "NUM_CHANNELS = 1\n",
    "# Número de classes\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Tamanho das imagens de entrada (largura, altura)\n",
    "INPUT_WIDTH = 128\n",
    "INPUT_HEIGHT = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f55c1",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05fb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, imagePaths, maskPaths, transforms):\n",
    "        # Caminhos para as imagens\n",
    "        self.imagePaths = imagePaths\n",
    "        # Caminhos para as máscaras\n",
    "        self.maskPaths = maskPaths\n",
    "        # Transformações\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Número de amostras no dataset\n",
    "        return len(self.imagePaths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Obtém o caminho para a imagem\n",
    "        imagePath = self.imagePaths[idx]\n",
    "        # Carrega a imagem\n",
    "        image = cv2.imread(imagePath)\n",
    "        # Converte de BGR para RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Carrega máscara de segmentação assiciada à imagem\n",
    "        mask = cv2.imread(self.maskPaths[idx], 0)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            # Apllica as transformações, caso existam\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask)\n",
    "        \n",
    "        # Retorna uma tupla com imagem e máscara\n",
    "        return (image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b42dac",
   "metadata": {},
   "source": [
    "## Definindo uma U-Net\n",
    "---\n",
    "* U-Net: A PyTorch Implementation in 60 lines of Code\n",
    "    * https://amaarora.github.io/2020/09/13/unet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0267acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inChannels, outChannels):\n",
    "        super().__init__()\n",
    "        # store the convolution and RELU layers\n",
    "        self.conv1 = nn.Conv2d(inChannels, outChannels, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(outChannels, outChannels, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CONV => RELU => CONV\n",
    "        return self.conv2(self.relu(self.conv1(x)))\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels=(3, 16, 32, 64)):\n",
    "        super().__init__()\n",
    "        # store the encoder blocks and maxpooling layer\n",
    "        self.encBlocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # initialize an empty list to store the intermediate outputs\n",
    "        blockOutputs = []\n",
    "        \n",
    "        # loop through the encoder blocks\n",
    "        for block in self.encBlocks:\n",
    "            # pass the inputs through the current encoder block, \n",
    "            x = block(x)\n",
    "            # store the outputs\n",
    "            blockOutputs.append(x)\n",
    "            # apply maxpooling on the output\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # return the list containing the intermediate outputs\n",
    "        return blockOutputs\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels=(64, 32, 16)):\n",
    "        super().__init__()\n",
    "        # Number of channels\n",
    "        self.channels = channels\n",
    "        # Upsampler blocks\n",
    "        self.upconvs = nn.ModuleList(\n",
    "            [nn.ConvTranspose2d(channels[i], channels[i + 1], 2, 2) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        # Decoder blocks\n",
    "        self.dec_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, encFeatures):\n",
    "        # loop through the number of channels\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            # pass the inputs through the upsampler blocks\n",
    "            x = self.upconvs[i](x)\n",
    "            # crop the current features from the encoder blocks,\n",
    "            encFeat = self.crop(encFeatures[i], x)\n",
    "            # concatenate them with the current upsampled features,\n",
    "            x = torch.cat([x, encFeat], dim=1)\n",
    "            # pass the concatenated output through the current decoder block\n",
    "            x = self.dec_blocks[i](x)\n",
    "\n",
    "        # return the final decoder output\n",
    "        return x\n",
    "    \n",
    "    def crop(self, encFeatures, x):\n",
    "        # Grab the dimensions of the inputs\n",
    "        (_, _, H, W) = x.shape\n",
    "        # Crop the encoder features to match the dimensions\n",
    "        encFeatures = transforms.CenterCrop([H, W])(encFeatures)\n",
    "        # Return the cropped features\n",
    "        return encFeatures\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encChannels=(3, 16, 32, 64),\n",
    "                 decChannels=(64, 32, 16),\n",
    "                 nbClasses=1, retainDim=True,\n",
    "                 outSize=(INPUT_HEIGHT, INPUT_WIDTH)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # initialize the encoder and decoder\n",
    "        self.encoder = Encoder(encChannels)\n",
    "        self.decoder = Decoder(decChannels)\n",
    "        \n",
    "        # initialize the regression head and store the class variables\n",
    "        self.head = nn.Conv2d(decChannels[-1], nbClasses, 1)\n",
    "        \n",
    "        self.retainDim = retainDim\n",
    "        self.outSize = outSize\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # grab the features from the encoder\n",
    "        encFeatures = self.encoder(x)\n",
    "        \n",
    "        # pass the encoder features through decoder making sure that\n",
    "        # their dimensions are suited for concatenation\n",
    "        decFeatures = self.decoder(encFeatures[::-1][0], \n",
    "                                   encFeatures[::-1][1:])\n",
    "        \n",
    "        # pass the decoder features through the regression head to obtain the segmentation mask\n",
    "        map = self.head(decFeatures)\n",
    "        \n",
    "        # if we are retaining the original output dimensions\n",
    "        #   then resize the output to match them\n",
    "        if self.retainDim:\n",
    "            map = F.interpolate(map, self.outSize)\n",
    "            \n",
    "        # Retorna o mapa de caracteristicas\n",
    "        return map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bc4e1",
   "metadata": {},
   "source": [
    "## Dividindo o dataset em treino e teste\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fafb3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m maskPaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MASK_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Divide o conjunto de dados. 15% para testes e 85% para treinamento.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m trainImages, testImages, trainMasks, testMasks \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagePaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mmaskPaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env-sin393-py39/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/env-sin393-py39/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-sin393-py39/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Carrega os caminhos para as imagens e coloca em ordem alfabética\n",
    "imagePaths = sorted(glob.glob(os.path.join(IMAGE_PATH, '*')))\n",
    "# Carrega os caminhos para as máscaras e coloca em ordem alfabética\n",
    "maskPaths = sorted(glob.glob(os.path.join(MASK_PATH, '*')))\n",
    "\n",
    "# Divide o conjunto de dados. 15% para testes e 85% para treinamento.\n",
    "trainImages, testImages, trainMasks, testMasks = train_test_split(imagePaths, \n",
    "                                                                  maskPaths, \n",
    "                                                                  test_size=0.15, \n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183b230",
   "metadata": {},
   "source": [
    "## Defininfo datasets e dataloaders\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininfo as transformações\n",
    "transforms_ = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Resize((INPUT_HEIGHT, INPUT_WIDTH)),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "# Criando os datasets\n",
    "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks, transforms=transforms_)\n",
    "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks, transforms=transforms_)\n",
    "print(f\"{len(trainDS)} images in the training set...\")\n",
    "print(f\"{len(testDS)} images in the test set...\")\n",
    "\n",
    "# Criando os dataloaders\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "                         batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
    "                         num_workers=os.cpu_count())\n",
    "testLoader = DataLoader(testDS, shuffle=False,\n",
    "                        batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
    "                        num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22f797",
   "metadata": {},
   "source": [
    "## Construindo o modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86314438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o modelo\n",
    "unet = UNet()\n",
    "\n",
    "# Envia o modelo para o DEVICE\n",
    "unet = unet.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda (loss) \n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "\n",
    "# Otimizador - SGD\n",
    "opt = Adam(unet.parameters(), lr=INIT_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para calcular as médias das perdas durante o treinamento\n",
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "testSteps = len(testDS) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d39c56",
   "metadata": {},
   "source": [
    "## Treinando o modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825939cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "# Listas contendo as perdas em cada época para treino e teste.\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    # Modo de treinamento\n",
    "    unet.train()\n",
    "    \n",
    "    # TRAINING\n",
    "    # ========\n",
    "    # Inicializa a perda do treinamento.\n",
    "    totalTrainLoss = 0\n",
    "    \n",
    "    # loop over the training set\n",
    "    for (i, (x, y)) in enumerate(trainLoader):\n",
    "        # send the input to the device\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        # >>>> FORWARD\n",
    "        pred = unet(x)\n",
    "        \n",
    "        # Calcula a perda (loss)\n",
    "        loss = lossFunc(pred, y)\n",
    "        \n",
    "        # Zera os gradientes acumulados.\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # <<<< BACKWARD\n",
    "        loss.backward()\n",
    "        \n",
    "        # Otimiza os parametros do modelo\n",
    "        opt.step()\n",
    "        \n",
    "        # Acumula a perda da época\n",
    "        totalTrainLoss += loss\n",
    "    \n",
    "    # VALIDATION\n",
    "    # ==========\n",
    "    # Inicializa a perda da época\n",
    "    totalTestLoss = 0\n",
    "    \n",
    "    # Desabilita o calculo do gradiente durante a validação\n",
    "    with torch.no_grad():\n",
    "        # Modo de avaliação\n",
    "        unet.eval()\n",
    "        \n",
    "        # loop over the validation set\n",
    "        for (x, y) in testLoader:\n",
    "            # Envia as entradas para o DEVICE\n",
    "            x = x.to(DEVICE) \n",
    "            y = y.to(DEVICE)\n",
    "            \n",
    "            # >>>> FORWARD \n",
    "            pred = unet(x)\n",
    "            \n",
    "            # Calcula a perda \n",
    "            loss = lossFunc(pred, y)\n",
    "            \n",
    "            # Acumula a perda da época\n",
    "            totalTestLoss += loss\n",
    "    \n",
    "    # Calcula as médias das perdas\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "    \n",
    "    # Atualiza as listas que contém os históricos de treinamento.\n",
    "    train_loss_list.append(avgTrainLoss.cpu().detach().numpy())\n",
    "    test_loss_list.append(avgTestLoss.cpu().detach().numpy())\n",
    "\n",
    "    # Printing...\n",
    "    print(\"EPOCH: {}/{}, Train loss: {:.6f}, Test loss: {:.4f}\".format(e + 1, NUM_EPOCHS, avgTrainLoss, avgTestLoss))\n",
    "\n",
    "# Tempo total do treinamento\n",
    "endTime = time.time()\n",
    "print(\"Time to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293762c",
   "metadata": {},
   "source": [
    "## Plota as curvas de treinamento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss_list, label=\"Train loss\")\n",
    "plt.plot(test_loss_list, label=\"Test loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631f7f7",
   "metadata": {},
   "source": [
    "## Plota os resultados da segmentação\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot(origImage, origMask, predMask):\n",
    "    figure, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "    # Imagem\n",
    "    ax[0].imshow(origImage)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    # Máscara\n",
    "    ax[1].imshow(origMask)\n",
    "    ax[1].set_title(\"Original Mask\")\n",
    "    # Predição\n",
    "    ax[2].imshow(predMask)\n",
    "    ax[2].set_title(\"Predicted Mask\")\n",
    "\n",
    "    figure.tight_layout()\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0042c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Algumas imagens. Para visualização.\n",
    "imagePaths = np.random.choice(testImages, size=10)\n",
    "# Todas as imagens. Para testes.\n",
    "### imagePaths = testImages\n",
    "\n",
    "# TESTE\n",
    "### print(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a830da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    # Modo de avaliação\n",
    "    unet.eval()\n",
    "    # Desabilita o calculo do gradiente\n",
    "    with torch.no_grad():\n",
    "        # Carrega a imagem\n",
    "        image = cv2.imread(imagePath)\n",
    "        # Converte BGR (padrão do OpenCV) para RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Converte a imagem de inteiro para float [0..1]\n",
    "        image = image.astype(\"float32\") / 255.0\n",
    "        \n",
    "        # Redimensiona a imagem\n",
    "        image = cv2.resize(image, (INPUT_HEIGHT, INPUT_HEIGHT))\n",
    "        # Gera uma cópia da imagem para visualização\n",
    "        orig = image.copy()\n",
    "        \n",
    "        # Gera o caminho para máscara baseado no caminho para a imagem.\n",
    "        filename = imagePath.split(os.path.sep)[-1]\n",
    "        groundTruthPath = os.path.join(MASK_PATH, filename)\n",
    "        # Carrega a máscara de segmentação ground-truth. Para avaliar a segmentação.\n",
    "        gtMask = cv2.imread(groundTruthPath, 0)\n",
    "        # Redimensiona a máscara.\n",
    "        gtMask = cv2.resize(gtMask, (INPUT_HEIGHT, INPUT_HEIGHT))\n",
    "        \n",
    "        # Converte HxWxC para CxHxW\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        # Adiciona uma dimensão. Gerando um lote com uma imagem.\n",
    "        image = np.expand_dims(image, 0)\n",
    "        # Cria um tensor PyTorch\n",
    "        image = torch.from_numpy(image)\n",
    "        # Envia o tensor para o DEVICE\n",
    "        image = image.to(DEVICE)\n",
    "        \n",
    "        # >>>> FORWARD\n",
    "        # Predição \n",
    "        predMask = unet(image).squeeze()\n",
    "        # Passa a predição por uma função sigmóide (apenas para segmentação em duas classes)\n",
    "        predMask = torch.sigmoid(predMask)\n",
    "        # Envia para a CPU e converte para NumPy array.\n",
    "        predMask = predMask.cpu().numpy()\n",
    "        \n",
    "        # Filtra predições fracas\n",
    "        predMask = (predMask > THRESHOLD) * 255\n",
    "        # Converte o resultado para inteiro\n",
    "        predMask = predMask.astype(np.uint8)\n",
    "        \n",
    "        # Plota o resultado da segmentação\n",
    "        prepare_plot(orig, gtMask, predMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f28aa",
   "metadata": {},
   "source": [
    "## Avaliando os resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5eae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637c464",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "---\n",
    "* U-Net: Training Image Segmentation Models in PyTorch\n",
    "    * https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/\n",
    "* U-Net: A PyTorch Implementation in 60 lines of Code\n",
    "    * https://amaarora.github.io/2020/09/13/unet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
